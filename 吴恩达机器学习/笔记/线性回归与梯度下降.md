
**什么是线性回归**<br>
线性回归是利用数理统计中回归分析，来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法，<br>
运用十分广泛。其表达形式为y = w'x+e，e为误差服从均值为0的正态分布，即给定一堆数据，找出一条直线<br>
来和这堆数据拟合。机器学习中实现线性回归的方法是梯度下降<br><br><br>

**梯度下降**<br>
梯度下降公式为:<br>
<a href="https://www.codecogs.com/eqnedit.php?latex=\Theta_i=\Theta_i-\alpha&space;\frac{\partial&space;}{\partial&space;x}&space;J(\Theta_1,\Theta&space;_2)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\Theta_i=\Theta_i-\alpha&space;\frac{\partial&space;}{\partial&space;x}&space;J(\Theta_1,\Theta&space;_2)" title="\Theta_i=\Theta_i-\alpha \frac{\partial }{\partial x} J(\Theta_1,\Theta _2)" /></a>
 <br>
 其中α是步长,α太小则梯度下降的速度太慢，阿尔法太大则可能跳过局部带价函数最低点，J(θ1，θ2)即为代价函数<br>
 
 **代价函数**<br>
 <a href="https://www.codecogs.com/eqnedit.php?latex=min=\frac{1}{2m}\sum_{1}^{m}(h\Theta&space;(x_i)-y_i)^2" target="_blank"><img src="https://latex.codecogs.com/gif.latex?min=\frac{1}{2m}\sum_{1}^{m}(h\Theta&space;(x_i)-y_i)^2" title="min=\frac{1}{2m}\sum_{1}^{m}(h\Theta (x_i)-y_i)^2" /></a>
<br>为何代价函数是除以2m而非m，因为无论除以哪个，最后所获得的的θ都是相同的，所以用2m做分母方便求偏微分
